{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VerlonRoelMBINGUI/AMMI_foundation_Deep-learning/blob/main/Verlon_Roel_MBINGUI_Pytorch_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## what is Pytorch\n",
        "\n",
        "![picture](https://cdn.analyticsvidhya.com/wp-content/uploads/2019/09/pytorch.png)\n",
        "\n",
        "PyTorch is a Python-based library used to build neural networks.\n",
        "\n",
        "It provides classes that allow us to easily develop a suite of deep learning models.\n",
        "\n",
        "It gives maximum flexibility and speed."
      ],
      "metadata": {
        "id": "hnZfVGFOPAWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install pytorch"
      ],
      "metadata": {
        "id": "d_MRnaAiO_Yf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_inaDm29O2Cs"
      },
      "outputs": [],
      "source": [
        "# !conda install pytorch torchvision -c pytorch\n",
        "# # or with GPU\n",
        "# ! conda install pytorch torchvision cudatoolkit=10.1 -c pytorch\n",
        "\n",
        "#https://pytorch.org/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Let's import pytorch and check that it's well installed"
      ],
      "metadata": {
        "id": "ZevvX0TWROTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kdo2d-DRHEb",
        "outputId": "07cc2b3f-c3a5-46f6-8492-d7def6fab94f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autograd\n",
        "\n",
        "### PyTorch uses a technique called automatic differentiation. It records all the operations that we are performing (computational graph) and replays it backward to compute gradients\n",
        "### The autograd package provides automatic differentiation for all operations on Tensors"
      ],
      "metadata": {
        "id": "5Gfz6GQaeWHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# requires_grad = True -> tracks all operations on the tensor. \n",
        "torch.manual_seed(42)\n",
        "w = torch.randn(3, requires_grad=True)\n",
        "print(w)\n",
        "y = w + 2\n",
        "# y was created as a result of an operation, so it has a grad_fn attribute.\n",
        "# grad_fn: references a Function that has created the Tensor\n",
        "print(y)\n",
        "y.retain_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3Oru6TXd_5h",
        "outputId": "9ced1137-4711-4926-f5f9-4f634f8274ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3367, 0.1288, 0.2345], requires_grad=True)\n",
            "tensor([2.3367, 2.1288, 2.2345], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-ep7mXOjV7a",
        "outputId": "0ef6ee50-0515-4e63-d395-4cebfc48d536"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<AddBackward0 object at 0x7f04fcacfa90>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = y * y * 3\n",
        "print(z)\n",
        "h = z.mean()\n",
        "print(h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9Qg94_HkL5I",
        "outputId": "1b068acb-17e0-4dee-c6bb-1fd5f74d2742"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([16.3804, 13.5955, 14.9785], grad_fn=<MulBackward0>)\n",
            "tensor(14.9848, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z.retain_grad()"
      ],
      "metadata": {
        "id": "6rfFQMHM9EBn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compute the gradients with backpropagation\n",
        "When we finish our computation we can call ***.backward()*** and have all the gradients computed automatically.\n",
        "The gradient for this tensor will be accumulated into .grad attribute.\n",
        "It is the partial derivate of the function w.r.t. the tensor.\n",
        "\n",
        "In summary, torch.autograd is an engine for computing vector-Jacobian product\n",
        "It computes partial derivates while applying the chain rule"
      ],
      "metadata": {
        "id": "CItPQk_xkuwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h.backward()\n",
        "#print(w.grad) # dh/dx"
      ],
      "metadata": {
        "id": "DqOwSvAjkT1d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## let's compute the gradient manually\n",
        "\n",
        "$δh/δw  = (δh/δz).(δz/δy).(δy/δw)$\n",
        "\n",
        "$δh/δz = 1/3$\n",
        "\n",
        "$δz/δy = 6y$\n",
        "\n",
        "$δy/δx = 1$\n",
        "\n",
        "$δh/δx = 1/3 * 6y * 1  = 2(w + 2)$"
      ],
      "metadata": {
        "id": "N8nbxK9NnraF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "2*(w + 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFAalYMwlYXw",
        "outputId": "65e4b069-63f2-4d67-fd4b-6fa7effc0441"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4.6734, 4.2576, 4.4689], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### grad w.r.t a non leaf tensor"
      ],
      "metadata": {
        "id": "saJGXCYece-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.grad)"
      ],
      "metadata": {
        "id": "PWPeTNwzclFn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e6e81d-99f0-4a9e-e857-796d9611b72a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([4.6734, 4.2576, 4.4689])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zeros gradient"
      ],
      "metadata": {
        "id": "0O6hz6V-lJPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "backward() accumulates the gradient for this tensor into .grad attribute. We need to be careful during optimization !!! Use .zero_() to empty the gradients before a new optimization step so that the parameter will be updated correctly. Otherwise, the gradient would be a combination of the old gradient, which we have already used to update our model parameters, and the newly-computed gradient. It would therefore point in some other direction than the intended direction towards the minimum "
      ],
      "metadata": {
        "id": "AAS6CL97paCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "    # just a dummy example\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "    \n",
        "    print(weights.grad)\n",
        "\n",
        "# print(weights)\n",
        "# print(model_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO3xwS1udcI9",
        "outputId": "ee981dd6-10be-40ce-b2af-6f5194f67335"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([6., 6., 6., 6.])\n",
            "tensor([9., 9., 9., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "    # just a dummy example\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "    \n",
        "    print(weights.grad)\n",
        "  \n",
        "    # this is important! It affects the final weights & output\n",
        "    weights.grad.zero_()\n",
        "\n",
        "# print(weights)\n",
        "# print(model_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5-WyAqbnkX6",
        "outputId": "9719d675-2cc0-4e44-9f42-ab5e00ab3bbb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backpropagation"
      ],
      "metadata": {
        "id": "SlJaQIbiu1OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "# This is the parameter we want to optimize -> requires_grad=True\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# forward pass to compute loss\n",
        "y_predicted = w * x\n",
        "\n",
        "loss = (y_predicted - y)**2\n",
        "print(loss)\n",
        "\n",
        "# backward pass to compute gradient dLoss/dw\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n",
        "\n",
        "# update weights, this operation should not be part of the computational graph\n",
        "with torch.no_grad():\n",
        "    w -= 0.01 * w.grad\n",
        "# don't forget to zero the gradients\n",
        "w.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXpyPij3u50R",
        "outputId": "488a6043-0655-476e-9ee2-1ef154b8832d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch optim module\n",
        "\n",
        "The Optim module in PyTorch has pre-written codes for most of the optimizers that are used while building a neural network. We just have to import them and then they can be used to build models."
      ],
      "metadata": {
        "id": "valeXz_Bslfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the optim module\n",
        "from torch import optim\n",
        "# sgd\n",
        "## SGD = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# adam\n",
        "## adam = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Optimizer has zero_grad() method\n",
        "# During training:\n",
        "# optimizer.step()\n",
        "# optimizer.zero_grad()"
      ],
      "metadata": {
        "id": "8S5yX5JUqdnF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Torch nn Module\n",
        "\n",
        "It provides an easy and modular way to build and train simple or complex neural networks using Torch:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Simple layers: nn.Linear\n",
        "*   Convolutional layers: nn.Conv1D, nn.Conv2D, ...\n",
        "*   Pooling layers: nn.MaxPool1d, nn.MaxPool2d, ....\n",
        "*   Criterion: nn.MSELoss, nn.CrossEntropyLoss\n",
        "*   Activation functions:  nn.ReLU, nn.Sigmoid, ...\n",
        "nn.RNN, nn.LSTM\n",
        "*   ....\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aiijWSXM4dcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "OZ3Lj0OAtHW2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear regression with pytorch"
      ],
      "metadata": {
        "id": "SzGiW9av55Xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "BjjbGCRf4q4G"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare data"
      ],
      "metadata": {
        "id": "Gkf-2lzg6cnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)\n",
        "\n",
        "# cast to float Tensor\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape"
      ],
      "metadata": {
        "id": "9Vehiuse6VYE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(n_samples, n_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp5LsUg26gdS",
        "outputId": "3efd65eb-46e0-4251-bab1-b56f02a9f16b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "NYpipihl7P50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear model f = wx + b\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)"
      ],
      "metadata": {
        "id": "w3U9R_ys6uDk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGhRht1-Llot",
        "outputId": "884097ed-a609-4c9b-8267-9740fff94d46"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1, out_features=1, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, w in model.named_parameters():\n",
        "  print(name)\n",
        "  print(w)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdDY1m1pMIs9",
        "outputId": "7603c577-d098-42bb-8a96-ab86e2cc10fb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight\n",
            "Parameter containing:\n",
            "tensor([[0.8815]], requires_grad=True)\n",
            "bias\n",
            "Parameter containing:\n",
            "tensor([-0.7336], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss and optimizer"
      ],
      "metadata": {
        "id": "f8vqMh1T7cno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
      ],
      "metadata": {
        "id": "9gIqng_f7VKw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "1T5vp2g07q4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_predicted = model(X)\n",
        "\n",
        "    ##compute the loss between your prediction and the true y\n",
        "    loss = criterion(y_predicted, y)\n",
        "    \n",
        "    # Backward pass \n",
        "    loss.backward()\n",
        "\n",
        "    ## update parameters\n",
        "    optimizer.step()\n",
        "    \n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "# Plot\n",
        "predicted = model(X).detach().numpy()\n",
        "\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "zl37Iv237hKa",
        "outputId": "2b46aab6-2a62-492d-f603-7a5ed718c9aa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 3972.3162\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch Dataset\n",
        "\n",
        "PyTorch provides two data primitives: `torch.utils.data.DataLoade`r and `torch.utils.data.Dataset` that allow us to use pre-loaded datasets as well as our own data. Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\n",
        "\n",
        "PyTorch domain libraries provide a number of pre-loaded datasets (such as FashionMNIST) that subclass torch.utils.data.Dataset and implement functions specific to the particular data. \n",
        "\n",
        "Dataset are accessible through  \n",
        "* TorchVision: for images dataset\n",
        "* TorchText: for text datasets\n",
        "* TorchAudio: for audios dataset\n",
        "\n",
        "\n",
        "Here is an example of how to load the Fashion-MNIST\n",
        "\n",
        "`root` is the path where the train/test data is stored,\n",
        "\n",
        "`train` specifies training or test dataset,\n",
        "\n",
        "`download=True` downloads the data from the internet if it’s not available at root.\n",
        "\n",
        "`transform` and target_transform specify the feature and label transformations (convert data to tensor, normalize data, ...(see documentation))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cndwit8l79ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()  \n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "vhU4nmvy8gHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4502b71-dc23-4e09-ac28-a3fc2156a4aa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 14980818.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 270437.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5118359.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 17540436.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7SVN5YUzuOB",
        "outputId": "0861451e-5fc3-49d2-ca01-86ef49dbd34a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size=16, shuffle=False)\n",
        "for image, label in train_dataloader:\n",
        "  print(image.shape)\n",
        "  print(label)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIhQzUV08gAY",
        "outputId": "01d5f2ec-c2ca-46a4-823e-c2944cd51b3c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 1, 28, 28])\n",
            "tensor([9, 0, 0, 3, 0, 2, 7, 2, 5, 5, 0, 9, 5, 5, 7, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX4P5S7ZzbJN",
        "outputId": "ccf08cb2-7bab-41d0-de20-86e4a425d4c1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3750"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Custom Dataset for your files\n",
        "\n",
        "A custom Dataset class must implement three functions: `__init__`, `__len__`, and `__getitem__`. "
      ],
      "metadata": {
        "id": "xjcAjd5vCrO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBEPF6tjW4-B",
        "outputId": "09ca801a-e86e-4992-f6f3-b762f3b902b8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rRyxUr-l1LL7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        # Initialize data, download, etc.\n",
        "        # read with numpy or pandas\n",
        "        xy = pd.read_csv('/content/drive/MyDrive/wine.csv')\n",
        "        \n",
        "        xy = xy.to_numpy()\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        # here the first column is the class label, the rest are the features\n",
        "        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\n",
        "        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ],
      "metadata": {
        "id": "alAzIhcS8f7T"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "dataset = WineDataset()\n",
        "\n",
        "# get first sample and unpack\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features, labels)\n",
        "\n",
        "print(features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaRC-t1z8fqy",
        "outputId": "9b8c79c5-8903-4a89-a330-6abfba59f1ab"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03], dtype=torch.float64) tensor([1.], dtype=torch.float64)\n",
            "torch.Size([13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using pytorch dataset transform on custom dataset"
      ],
      "metadata": {
        "id": "_AloVEw_-Cjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WineDataset1(Dataset):\n",
        "\n",
        "    def __init__(self, transform=None):\n",
        "        # Initialize data, download, etc.\n",
        "        # read with numpy or pandas\n",
        "        xy = pd.read_csv('/content/drive/MyDrive/wine.csv')\n",
        "        \n",
        "        xy = xy.to_numpy()\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        # here the first column is the class label, the rest are the features\n",
        "        self.x_data = xy[:, 1:] # size [n_samples, n_features]\n",
        "        self.y_data = xy[:, [0]] # size [n_samples, 1]\n",
        "        self.transform = transform\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        sample =  self.x_data[index], self.y_data[index]\n",
        "        if self.transform:\n",
        "          sample = self.transform(sample)\n",
        "        return sample\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "class ToTensor:\n",
        "  def __call__(self, sample):\n",
        "    inputs, target = sample\n",
        "    return torch.from_numpy(inputs), torch.from_numpy(target)\n"
      ],
      "metadata": {
        "id": "BqZieX34-I2R"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "dataset1 = WineDataset1(transform=ToTensor())\n",
        "\n",
        "# get first sample and unpack\n",
        "first_data = dataset1[0]\n",
        "features, labels = first_data\n",
        "print(features, labels)\n",
        "\n",
        "print(features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QgOsFxx_F7o",
        "outputId": "5b5a304e-79ec-4e3b-be2f-743f42de7bbc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03], dtype=torch.float64) tensor([1.], dtype=torch.float64)\n",
            "torch.Size([13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Dataloader for our custum dataset"
      ],
      "metadata": {
        "id": "HyJjntGWADZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load whole dataset with DataLoader\n",
        "# shuffle: shuffle data, good for training\n",
        "train_loader = DataLoader(dataset=dataset1,\n",
        "                          batch_size=4,\n",
        "                          shuffle=True)\n",
        "\n",
        "# convert to an iterator and look at one random sample\n",
        "dataiter = iter(train_loader)\n",
        "data = next(dataiter)\n",
        "features, labels = data\n",
        "print(features, labels)\n",
        "print(features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMqU9t2p8fnV",
        "outputId": "28eaaa42-dcb3-4670-c456-d1ab007a80ff"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.4160e+01, 2.5100e+00, 2.4800e+00, 2.0000e+01, 9.1000e+01, 1.6800e+00,\n",
            "         7.0000e-01, 4.4000e-01, 1.2400e+00, 9.7000e+00, 6.2000e-01, 1.7100e+00,\n",
            "         6.6000e+02],\n",
            "        [1.4390e+01, 1.8700e+00, 2.4500e+00, 1.4600e+01, 9.6000e+01, 2.5000e+00,\n",
            "         2.5200e+00, 3.0000e-01, 1.9800e+00, 5.2500e+00, 1.0200e+00, 3.5800e+00,\n",
            "         1.2900e+03],\n",
            "        [1.4830e+01, 1.6400e+00, 2.1700e+00, 1.4000e+01, 9.7000e+01, 2.8000e+00,\n",
            "         2.9800e+00, 2.9000e-01, 1.9800e+00, 5.2000e+00, 1.0800e+00, 2.8500e+00,\n",
            "         1.0450e+03],\n",
            "        [1.2160e+01, 1.6100e+00, 2.3100e+00, 2.2800e+01, 9.0000e+01, 1.7800e+00,\n",
            "         1.6900e+00, 4.3000e-01, 1.5600e+00, 2.4500e+00, 1.3300e+00, 2.2600e+00,\n",
            "         4.9500e+02]], dtype=torch.float64) tensor([[3.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [2.]], dtype=torch.float64)\n",
            "torch.Size([4, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's see how to train with the dataloader"
      ],
      "metadata": {
        "id": "pYWQdtA4FYpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy Training loop\n",
        "num_epochs = 2\n",
        "n_iterations = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        \n",
        "        # Run your training process\n",
        "        if (i+1) % 5 == 0:\n",
        "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_crjXXu8fig",
        "outputId": "9d7ff019-7182-4245-f08c-e1d796db1b8d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/2, Step 5/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 10/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 15/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 20/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 25/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 30/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 35/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 40/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 45/10| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n",
            "Epoch: 2/2, Step 5/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 10/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 15/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 20/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 25/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 30/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 35/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 40/10| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 45/10| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activation functions"
      ],
      "metadata": {
        "id": "XPNNUPz98BMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x = torch.tensor([-1.0, 1.0, 2.0, 3.0])"
      ],
      "metadata": {
        "id": "vkS1AGFJ8iWm"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sigmoid"
      ],
      "metadata": {
        "id": "HyGosyvqH4Ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = torch.sigmoid(x)\n",
        "print(output)\n",
        "s = nn.Sigmoid()\n",
        "output = s(x)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTooUT_O8iDi",
        "outputId": "a390dc72-f002-471a-ed13-2133fea5a46b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
            "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tanh"
      ],
      "metadata": {
        "id": "nMNTcEdoIAG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = torch.tanh(x)\n",
        "print(output)\n",
        "t = nn.Tanh()\n",
        "output = t(x)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWAUCMYs8h8I",
        "outputId": "933c6a49-a70a-4742-cd0f-1688a0052339"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
            "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Relu"
      ],
      "metadata": {
        "id": "DXLXgwqPIIWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = torch.relu(x)\n",
        "print(output)\n",
        "relu = nn.ReLU()\n",
        "output = relu(x)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlLEFTbvIK8S",
        "outputId": "54b532b2-b64a-43e6-b5d6-c833ff878b45"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 1., 2., 3.])\n",
            "tensor([0., 1., 2., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## leaky relu"
      ],
      "metadata": {
        "id": "tG4ic0eCIQRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "output = F.leaky_relu(x)\n",
        "print(output)\n",
        "lrelu = nn.LeakyReLU()\n",
        "output = lrelu(x)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwcEErxUIOF-",
        "outputId": "9321ccb6-bf13-46b9-d98e-c59be58feb0c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n",
            "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#softmax"
      ],
      "metadata": {
        "id": "LyUf339BHwSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = torch.softmax(x, dim=0)\n",
        "print(output)\n",
        "sm = nn.Softmax(dim=0)\n",
        "output = sm(x)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJhC_Lvm8iPF",
        "outputId": "0b29c851-397d-4174-f46e-b401c8718519"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
            "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feedforward network"
      ],
      "metadata": {
        "id": "cJtgNdkz8XFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tFlWUr1p7t7y"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load MNIST dataset from torchvision\n"
      ],
      "metadata": {
        "id": "n-wxOY2BJHz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST dataset \n",
        "batch_size = 16\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),  \n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "print(example_data.shape)\n",
        "print(example_targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuDIMWKWJC6O",
        "outputId": "243bbe39-6af9-47e6-91ed-5aaf886779f1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 101628500.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 31471991.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 25168922.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 14710833.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "torch.Size([16, 1, 28, 28])\n",
            "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "S3BRg1caJYgM",
        "outputId": "9e63270e-e1f1-43b9-a5b8-ea7f43e59c91"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Model using torch nn Module"
      ],
      "metadata": {
        "id": "-WsYUsX7Jh3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_classes = num_classes\n",
        "        ## add a linear layer\n",
        "        self.l1 = nn.Linear(self.input_size,self.hidden_size )\n",
        "\n",
        "        ## add relu activation\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        ## add linear layer\n",
        "        self.l2 = nn.Linear(self.hidden_size ,self.num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        ## fit the data x to the first layer\n",
        "        out = self.l1(x)\n",
        "\n",
        "        ## apply non linearity to the output of the first layer\n",
        "        out = self.relu(out)\n",
        "\n",
        "        ## pass the output to the last layer\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out"
      ],
      "metadata": {
        "id": "010CHXZOJd1p"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set hyper-parameters"
      ],
      "metadata": {
        "id": "wY-wRx-8RSDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters \n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500 \n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 16\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "JH5PhbVrRQ63"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
      ],
      "metadata": {
        "id": "nv-hPXBqJnP_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "RuJQTQz2JvFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "#   if os.path.exists(\"model_weights.pth\"):\n",
        "    # model.load_state_dict(torch.load('model_weights.pth'))\n",
        "  for i, (images, labels) in enumerate(train_loader):  \n",
        "      # origin shape: [16, 1, 28, 28]\n",
        "      # resized: [16, 784]\n",
        "      images = images.reshape(-1, 28*28).to(device)\n",
        "      labels = labels.to(device)\n",
        "      \n",
        "      # Forward pass\n",
        "      outputs = model(images)\n",
        "\n",
        "      ## compute the loss between output and labels\n",
        "      loss = criterion(outputs, labels)\n",
        "      \n",
        "      # Backward pass\n",
        "      loss.backward()\n",
        "    \n",
        "\n",
        "      ## update parameters\n",
        "      optimizer.step()\n",
        "      \n",
        "\n",
        "      ## zeros the gradient\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      if (i+1) % 100 == 0:\n",
        "          print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9p3FM_AJuIZ",
        "outputId": "27499887-6426-4b69-be1b-091be0fa938c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Loss: 0.5345\n",
            "Epoch [1/2], Loss: 0.2177\n",
            "Epoch [1/2], Loss: 0.0851\n",
            "Epoch [1/2], Loss: 0.1398\n",
            "Epoch [1/2], Loss: 0.2222\n",
            "Epoch [1/2], Loss: 0.1905\n",
            "Epoch [1/2], Loss: 0.2100\n",
            "Epoch [1/2], Loss: 0.3135\n",
            "Epoch [1/2], Loss: 0.0910\n",
            "Epoch [1/2], Loss: 0.2005\n",
            "Epoch [1/2], Loss: 0.0334\n",
            "Epoch [1/2], Loss: 0.0557\n",
            "Epoch [1/2], Loss: 0.0075\n",
            "Epoch [1/2], Loss: 0.1065\n",
            "Epoch [1/2], Loss: 0.2470\n",
            "Epoch [1/2], Loss: 0.1921\n",
            "Epoch [1/2], Loss: 0.1159\n",
            "Epoch [1/2], Loss: 0.0907\n",
            "Epoch [1/2], Loss: 0.0568\n",
            "Epoch [1/2], Loss: 0.1031\n",
            "Epoch [1/2], Loss: 0.3850\n",
            "Epoch [1/2], Loss: 0.0888\n",
            "Epoch [1/2], Loss: 0.1280\n",
            "Epoch [1/2], Loss: 0.0349\n",
            "Epoch [1/2], Loss: 0.0200\n",
            "Epoch [1/2], Loss: 0.0956\n",
            "Epoch [1/2], Loss: 0.7068\n",
            "Epoch [1/2], Loss: 0.0020\n",
            "Epoch [1/2], Loss: 0.1557\n",
            "Epoch [1/2], Loss: 0.1113\n",
            "Epoch [1/2], Loss: 0.0928\n",
            "Epoch [1/2], Loss: 0.0161\n",
            "Epoch [1/2], Loss: 0.0536\n",
            "Epoch [1/2], Loss: 0.1266\n",
            "Epoch [1/2], Loss: 0.1896\n",
            "Epoch [1/2], Loss: 0.0472\n",
            "Epoch [1/2], Loss: 0.4489\n",
            "Epoch [2/2], Loss: 0.0639\n",
            "Epoch [2/2], Loss: 0.2708\n",
            "Epoch [2/2], Loss: 0.4668\n",
            "Epoch [2/2], Loss: 0.0131\n",
            "Epoch [2/2], Loss: 0.0916\n",
            "Epoch [2/2], Loss: 0.0455\n",
            "Epoch [2/2], Loss: 0.1443\n",
            "Epoch [2/2], Loss: 0.3484\n",
            "Epoch [2/2], Loss: 0.0390\n",
            "Epoch [2/2], Loss: 0.1406\n",
            "Epoch [2/2], Loss: 0.0791\n",
            "Epoch [2/2], Loss: 0.0545\n",
            "Epoch [2/2], Loss: 0.0761\n",
            "Epoch [2/2], Loss: 0.0322\n",
            "Epoch [2/2], Loss: 0.1556\n",
            "Epoch [2/2], Loss: 0.0089\n",
            "Epoch [2/2], Loss: 0.1026\n",
            "Epoch [2/2], Loss: 0.0135\n",
            "Epoch [2/2], Loss: 0.3768\n",
            "Epoch [2/2], Loss: 0.0073\n",
            "Epoch [2/2], Loss: 0.0112\n",
            "Epoch [2/2], Loss: 0.0164\n",
            "Epoch [2/2], Loss: 0.1319\n",
            "Epoch [2/2], Loss: 0.3010\n",
            "Epoch [2/2], Loss: 0.2126\n",
            "Epoch [2/2], Loss: 0.0848\n",
            "Epoch [2/2], Loss: 0.0021\n",
            "Epoch [2/2], Loss: 0.1771\n",
            "Epoch [2/2], Loss: 0.0509\n",
            "Epoch [2/2], Loss: 0.1257\n",
            "Epoch [2/2], Loss: 0.2364\n",
            "Epoch [2/2], Loss: 0.2531\n",
            "Epoch [2/2], Loss: 0.0072\n",
            "Epoch [2/2], Loss: 0.0895\n",
            "Epoch [2/2], Loss: 0.0026\n",
            "Epoch [2/2], Loss: 0.0290\n",
            "Epoch [2/2], Loss: 0.3094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the model"
      ],
      "metadata": {
        "id": "DJtdpX5XQH7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V06y8gbrKYIC",
        "outputId": "d90c9cea-a0c0-4153-fc30-a557cd115f0c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 97.64 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and loading models"
      ],
      "metadata": {
        "id": "2jG9BSotRM-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "QNFs4X5XRQ3I"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJvZDx5dRW_p",
        "outputId": "cd5add3a-53d7-4bb4-be6f-7dfd99bdef8f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra reading\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html"
      ],
      "metadata": {
        "id": "T8zx-Lx-QNDD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tdPHkhJQLXhf"
      },
      "execution_count": 49,
      "outputs": []
    }
  ]
}